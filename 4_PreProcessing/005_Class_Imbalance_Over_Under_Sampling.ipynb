{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 클래스 불균형 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 불균형 되어 있는 순간, 이 모델 입장에서는 다수 클래스로 많이 판별하는게 이득. 그렇게 학습될 가능성이 매우 큼. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![5_20.png](../materials/5_20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![5_20.png](../materials/5_21.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대부분 분류 모형이 정확도만 최대화 하려고 함. 때문에, 효율적으로 분류하다 보면 이런 문제들이 매우 자주 발생함. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![5_20.png](../materials/5_22.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 두 경우의 경우 대부분의 모델은 왼쪽이 좋다고 판단한다. \n",
    "- 하지만, 상황에 따라 그렇지 않은 경우도 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![5_20.png](../materials/5_23.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위처럼 꼭 불균형 된다고 해서, 꼭 안좋은 모델이 나오는 것만도 아니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN for diagnose Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![5_20.png](../materials/5_24.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-nearest는 클래스 불균형에 매우 민감하다. \n",
    "- 때문에, 클래스 불균형 문제가 있는 경우에는 사용하면 안되는 모델이지만, \n",
    "- 역으로 활용해서 **클래스 불균형 문제를 테스트** 하는데 쓸 수 있다. \n",
    "- K-Nearest에서 K가 클수록 민감해진다. \n",
    "    - 당연히 그렇겠지. \n",
    "    - 극단적으로 소수 샘플이 10개밖에 없는데, K값을 21로 잡았다면? 그럼 무슨 짓을 해도, 소수 클래스 군집이 될 수가 없음. \n",
    "    - K=11을 많이 선호한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![5_20.png](../materials/5_25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적인 아이디어는, 최대한 소수 클래스로 분류하려는 시도임. \n",
    "- 위에 보면, 어느정도 정확도를 손해봤지. 결국 그렇게 해보겠다는거야. \n",
    "- 그런데 이론적으로 그렇다는 거고, 같이 오르는 경우도 있고 케이스 매우 다양하다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Sampling\n",
    "## Over Sampling and Under Sampling\n",
    "\n",
    "- [datascienceschoo.net](https://datascienceschool.net/03%20machine%20learning/14.02%20%EB%B9%84%EB%8C%80%EC%B9%AD%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%AC%B8%EC%A0%9C.html?highlight=smote)\n",
    "- [saanghyuk github](https://github.com/saanghyuk/0B-python/blob/master/data_analysis/5_10_Model_Optimization.ipynb)\n",
    "- Test Data에는 절대 쓰는 것 아니다. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![5_27.png](../materials/5_27.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![5_27.png](../materials/5_28.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SMOTE는 소수만 돈다. \n",
    "- 이웃 K개를 바라본다. \n",
    "- 이웃 가운데 하나를 랜덤하게 선택한다. \n",
    "- 그 선택된 이웃과 나 사이 정중앙에 샘플을 생성한다. \n",
    "\n",
    "\n",
    "DTSCHOOL에서 나온 방식은\n",
    "- 마이너인 데이터를 싹다 돌면서 데이터를 하나 고르고, 주변 neighborhood를 찾는다. 보통은 KNN으로 찾는다.\n",
    "- 예를 들어 KNN에서 K=3이면, 마이너중에 하나 고르고 가장 가까운 동료 마이너를 3개 찾는다. 그 3개를 조합해서 새로운 데이터를 하나 만든다.\n",
    "- 그 다음 마이너 골라서 똑같이 해서 또 데이터 만든다. 이렇게 반복하는 과정.\n",
    "- 즉, 모든 데이터를 돌면서 업샘플을 하는 과정이다.\n",
    "\n",
    "찾아보니깐, 위 방법(DT말고 여기서 나온 방법)이 맞는듯. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![5_27.png](../materials/5_29.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![5_27.png](../materials/5_30.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**fit_resample**로 바뀌었음. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 보통 5:5로 하긴 하는데, 그렇게 하면 재현율이 너무 오르고 정확도 너무 떨어지는 경우도 많다. \n",
    "- 다수:소수가 보통 3:1, 4:1 정도 되게 만들어 보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래는 파란색이 다수, 빨간색이 소수인 상황. \n",
    "- 언더샘플링이니깐, 파란색을 제거해야 하는 상황. \n",
    "- 모든 파란색 샘플에서, 가장 가까운 n개의 소수 클래스까지의 거리를 평균친다. \n",
    "- 그게 짧은 애부터 날린다. \n",
    "- 보통은 그냥 n을 전체 소수 클래스 갯수로 써버린다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![5_27.png](../materials/5_31.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![5_27.png](../materials/5_32.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. NearMiss – Version 1 : It selects samples of the majority class for which average distances to the k closest instances of the minority class is smallest.\n",
    "2. NearMiss – Version 2 : It selects samples of the majority class for which average distances to the k farthest instances of the minority class is smallest.\n",
    "3. NearMiss – Version 3 : It works in 2 steps. Firstly, for each minority class instance, their M nearest-neighbors will be stored. Then finally, the majority class instances are selected for which the average distance to the N nearest-neighbors is the largest.\n",
    "    - Version 3 is different. This version will pick balanced clusters of points that are closest to outlier points from other classes, instead of building giant blob(s) around one or a handful of such points.\n",
    "    - 요약하자면, 그냥 소수 클래스 근처에 있는 애들은 남기고, 다수 클래스인데 멀리 떨어져있는 애들은 날린다는 것. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over Sampling Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir(r\"/Users/sanghyuk/Documents/preprocessing_python/lecture_source/5. 머신러닝 모델의 성능 향상을 위한 전처리/데이터/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Secom.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특징과 라벨 분리\n",
    "X = df.drop('Y', axis = 1)\n",
    "Y = df['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터와 평가 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1175, 590)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특징이 매우 많음을 확인\n",
    "Train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1101\n",
       " 1      74\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 불균형 확인 => 언더샘플링을 적용하기에는 부적절 \n",
    "Train_Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.878378378378379"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 불균형 비율 계산\n",
    "Train_Y.value_counts().iloc[0] / Train_Y.value_counts().iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제로도 class imbalance 문제가 있으면, recall이 거의 0에 가깝게 나옴. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.923469387755102\n"
     ]
    }
   ],
   "source": [
    "# kNN을 사용한 클래스 불균형 테스트\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.metrics import *\n",
    "kNN_model = KNN(n_neighbors = 11).fit(Train_X, Train_Y)\n",
    "pred_Y = kNN_model.predict(Test_X)\n",
    "print(recall_score(Test_Y, pred_Y))\n",
    "print(accuracy_score(Test_Y, pred_Y))\n",
    "\n",
    "# 재현율이 0%로 불균형이 심각한 수준이라 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# SMOTE 인스턴스 생성\n",
    "oversampling_instance = SMOTE(k_neighbors = 3)\n",
    "\n",
    "# 오버샘플링 적용\n",
    "o_Train_X, o_Train_Y = oversampling_instance.fit_resample(Train_X, Train_Y)\n",
    "\n",
    "# ndarray 형태가 되므로 다시 DataFrame과 Series로 변환 (남은 전처리가 없다면 하지 않아도 무방)\n",
    "o_Train_X = pd.DataFrame(o_Train_X, columns = X.columns)\n",
    "o_Train_Y = pd.Series(o_Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    1101\n",
       "-1    1101\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 비율이 1:1이 됨을 확인\n",
    "o_Train_Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5333333333333333\n",
      "0.6071428571428571\n"
     ]
    }
   ],
   "source": [
    "# 같은 모델로 다시 평가: 정확도는 감소했으나, 재현율이 크게 오름을 확인\n",
    "kNN_model = KNN(n_neighbors = 11).fit(o_Train_X, o_Train_Y)\n",
    "pred_Y = kNN_model.predict(Test_X)\n",
    "print(recall_score(Test_Y, pred_Y))\n",
    "print(accuracy_score(Test_Y, pred_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아까 0과 비교하면, 굉장히 많이 올랐음. accuracy희생도 컸음. <br>\n",
    "비율을 1:1말고, 2:1 정도로 다시 조정해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# SMOTE 인스턴스 생성\n",
    "oversampling_instance = SMOTE(k_neighbors = 3, sampling_strategy = {1:int(Train_Y.value_counts().iloc[0] / 2),\n",
    "                                                                    -1:Train_Y.value_counts().iloc[0]})\n",
    "\n",
    "# 오버샘플링 적용\n",
    "o_Train_X, o_Train_Y = oversampling_instance.fit_resample(Train_X, Train_Y)\n",
    "\n",
    "# ndarray 형태가 되므로 다시 DataFrame과 Series로 변환 (남은 전처리가 없다면 하지 않아도 무방)\n",
    "o_Train_X = pd.DataFrame(o_Train_X, columns = X.columns)\n",
    "o_Train_Y = pd.Series(o_Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43333333333333335\n",
      "0.7193877551020408\n"
     ]
    }
   ],
   "source": [
    "kNN_model = KNN(n_neighbors = 11).fit(o_Train_X, o_Train_Y)\n",
    "pred_Y = kNN_model.predict(Test_X)\n",
    "print(recall_score(Test_Y, pred_Y))\n",
    "print(accuracy_score(Test_Y, pred_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under Sampling Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir(r\"/Users/sanghyuk/Documents/preprocessing_python/lecture_source/5. 머신러닝 모델의 성능 향상을 위한 전처리/데이터/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"page-blocks0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특징과 라벨 분리\n",
    "X = df.drop('Class', axis = 1)\n",
    "Y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터와 평가 데이터 분할\n",
    "from sklearn.model_selection import train_test_split\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    3688\n",
       "positive     416\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 불균형 확인\n",
    "Train_Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Y.replace({\"negative\":-1, \"positive\":1}, inplace = True)\n",
    "Test_Y.replace({\"negative\":-1, \"positive\":1}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.865384615384615"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스 불균형 비율 계산\n",
    "Train_Y.value_counts().iloc[0] / Train_Y.value_counts().iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 정도도 꽤 심각한 수준이라고 볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6433566433566433\n",
      "0.9546783625730995\n"
     ]
    }
   ],
   "source": [
    "# kNN을 사용한 클래스 불균형 테스트\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.metrics import *\n",
    "kNN_model = KNN(n_neighbors = 11).fit(Train_X, Train_Y)\n",
    "pred_Y = kNN_model.predict(Test_X)\n",
    "print(recall_score(Test_Y, pred_Y))\n",
    "print(accuracy_score(Test_Y, pred_Y))\n",
    "\n",
    "# 재현율이 60%로 불균형이 심각한 수준은 아니라고 보임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아까에 비하면, 나쁘지는 않은데? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "NM_model = NearMiss(version = 2) \n",
    "\n",
    "# NearMiss 적용\n",
    "u_Train_X, u_Train_Y = NM_model.fit_resample(Train_X, Train_Y)\n",
    "u_Train_X = pd.DataFrame(u_Train_X, columns = X.columns)\n",
    "u_Train_Y = pd.Series(u_Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_jobs': None,\n",
       " 'n_neighbors': 3,\n",
       " 'n_neighbors_ver3': 3,\n",
       " 'sampling_strategy': 'auto',\n",
       " 'version': 2}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NM_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    416\n",
       "-1    416\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_Train_Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n",
      "0.22587719298245615\n"
     ]
    }
   ],
   "source": [
    "# kNN 재적용을 통한 성능 변화 확인\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.metrics import *\n",
    "kNN_model = KNN(n_neighbors = 11).fit(u_Train_X, u_Train_Y)\n",
    "pred_Y = kNN_model.predict(Test_X)\n",
    "print(recall_score(Test_Y, pred_Y))\n",
    "print(accuracy_score(Test_Y, pred_Y))\n",
    "\n",
    "# 재현율은 크게 올랐으나, 정확도가 크게 떨어짐 => 적당한 비율에 맞게 설정해야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도가 무슨 22%가 되네. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "NM_model = NearMiss(version = 2, sampling_strategy = {1:u_Train_Y.value_counts().iloc[-1],\n",
    "                                                      -1:u_Train_Y.value_counts().iloc[-1] * 5}) # 5:1 정도의 비율로 언더샘플링 재수행\n",
    "\n",
    "u_Train_X, u_Train_Y = NM_model.fit_resample(Train_X, Train_Y)\n",
    "u_Train_X = pd.DataFrame(u_Train_X, columns = X.columns)\n",
    "u_Train_Y = pd.Series(u_Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    2080\n",
       " 1     416\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_Train_Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8321678321678322\n",
      "0.6615497076023392\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.metrics import *\n",
    "kNN_model = KNN(n_neighbors = 11).fit(u_Train_X, u_Train_Y)\n",
    "pred_Y = kNN_model.predict(Test_X)\n",
    "print(recall_score(Test_Y, pred_Y))\n",
    "print(accuracy_score(Test_Y, pred_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
